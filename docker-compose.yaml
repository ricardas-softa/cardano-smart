services:
  ollama-service:
    image: ollama/ollama:latest
    volumes:
      - ./models:/root/.ollama
    pull_policy: always
    ports:
      - "11434:11434"
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - private-network

  init-ollama:
      image: alpine:latest
      depends_on:
        - ollama-service
      entrypoint: ["/bin/sh", "-c", "apk add --no-cache curl && while ! curl -sf http://ollama-service:11434/api/tags; do echo waiting for ollama-service; sleep 5; done; curl -X POST http://ollama-service:11434/api/pull -d '{\"name\": \"gemma3:27b\"}' && curl -X POST http://ollama-service:11434/api/pull -d '{\"name\": \"nomic-embed-text\"}'"]
      networks:
        - private-network

  doc-scraper:
    build:
      context: ./doc-scraper
      dockerfile: Dockerfile
    user: "1000:1000"
    volumes:
      - ./shared-data:/app/data
    environment:
      OUTPUT_PATH: "/app/data"
    networks:
      - private-network

  private-gpt-service:
    build:
      context: ./private-gpt
      dockerfile: Dockerfile
    user: "1000:1000"
    volumes:
      - ./private-gpt/local_data:/home/worker/app/local_data
      - ./shared-data:/home/worker/app/docs
    ports:
      - 8001:8001
    environment:
      PORT: 8001
      PGPT_PROFILES: docker
      PGPT_MODE: ollama
    depends_on:
      init-ollama:
        condition: service_completed_successfully
      doc-scraper:
        condition: service_completed_successfully
    networks:
      - private-network

  frontend-service:
    build: frontend
    volumes:
      - ./shared-data:/mnt/shared
      - ./frontend/data:/app/data
    ports:
      - "80:3000"
    depends_on:
      - private-gpt-service
    networks:
      - private-network

networks:
  private-network:
    driver: bridge
